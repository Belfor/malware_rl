import os
import sys
import random
from collections import OrderedDict
import numpy as np
import gym
from gym import spaces

from malware_rl.envs.utils import interface, malconv
from malware_rl.envs.controls import modifier

module_path = os.path.split(os.path.abspath(sys.modules[__name__].__file__))[0]

ACTION_LOOKUP = {
    i: act for i, act in enumerate(modifier.ACTION_TABLE.keys())
}

malicious_threshold = 0.5  # hardcode here for now
mc = malconv.MalConv()

class MalConvEnv(gym.Env):
    """Create MalConv gym interface"""
    metadata = {'render.modes': ['human']}

    def __init__(self, sha256list, random_sample=True, maxturns=5, output_path='malware_rl/data/evaded/malconv'):
        super(MalConvEnv, self).__init__()
        self.available_sha256 = sha256list
        self.action_space = spaces.Discrete(len(ACTION_LOOKUP))
        self.observation_space = np.zeros(1024**2)
        self.maxturns = maxturns
        self.feature_extractor = mc.extract
        self.output_path = output_path
        self.random_sample = random_sample
        self.history = OrderedDict()
        self.sample_iteration_index = 0

        self.output_path = os.path.join(
            os.path.dirname(
                os.path.dirname(
                    os.path.dirname(
                        os.path.abspath(__file__)))), output_path)

    def step(self, action_ix):
        # Execute one time step within the environment
        self.turns +=1
        self._take_action(action_ix)
        self.observation_space = self.feature_extractor(self.bytez)
        self.score = mc.predict_sample(self.observation_space)

        if self.score < malicious_threshold:
            reward = 10.0
            episode_over = True
            self.history[self.sha256]['evaded'] = True
        
        elif self.turns >= self.maxturns:
            # game over - max turns hit
            reward = self.original_score - self.score
            episode_over = True
        
        else:
            reward = self.original_score - self.score
            episode_over = False

        if episode_over:
            print('Episode over: reward = {}'.format(reward))

        return self.observation_space, reward, episode_over, {}


    def _take_action(self, action_ix):
        action = ACTION_LOOKUP[action_ix]
        print("ACTION:", action)
        self.history[self.sha256]['actions'].append(action)
        self.bytez = modifier.modify_sample(self.bytez, action)

    def reset(self):
        # Reset the state of the environment to an initial state
        self.turns = 0
        while True:
            # grab a new sample (TODO)
            if self.random_sample:
                self.sha256 = random.choice(self.available_sha256)
            else:
                self.sha256 = self.available_sha256[
                    self.sample_iteration_index % len(self.available_sha256)
                ]
                self.sample_iteration_index += 1
            
            self.history[self.sha256] = {'actions': [], 'evaded': False}
            self.bytez = interface.fetch_file(os.path.join(module_path, 'utils/samples/') + self.sha256)

            self.observation_space = self.feature_extractor(self.bytez)
            self.original_score = mc.predict_sample(self.observation_space)
            if self.original_score < malicious_threshold:
                continue # already labeled benign, skip

            break

        return self.observation_space

    def render(self, mode='human', close=False):
        # Render the environment to the screen
        pass

if __name__ == "__main__":
    import malconv_gym
    import random
    g = malconv_gym.MalConvEnv(5)
    g.reset()
    while True:
        _action = random.randint(0,len(ACTION_LOOKUP)-1)
        _, reward, done, _ = g.step(_action)
        if done:
            break
