# MalwareRL
> Malware Bypass Research using Reinforcement Learning

## Background
This is a malware manipulation environment using OpenAI's gym environments. The core idea is based on paper "Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning" 
([paper](https://arxiv.org/abs/1801.08917)) which myself and fellow Endgame data scientists collaborated on. I am extending the original repo because: 
1. It is no longer maintained
2. It leverages an outdated version of LIEF
3. I wanted to integrated new Malware gym environments and additional manipulations

Over the past three years there has been significant open-source projects published in the security machine learning space. In particular, [Ember](https://github.com/endgameinc/ember) (Endgame Malware BEnchmark for Research
) and MalConv: Malware detection by eating a whole exe ([paper](https://arxiv.org/abs/1804.04637)) have provided security researchers the ability to develop sophoticated, reproducible models that replicate techniques found in NGAVs.

## Objective
MalwareRL exposes `gym` environments for both Ember and MalConv to allow researchers to develop Reinforcement Learning agents to bypass realistic AVs. Actions include a variety of non-breaking (e.g. binaries will still execute) modifications to the PE header, sections, imports and overlay.

A baseline `RandomAgent` is provided to demonstrate how to interact w/ `gym` environments and expected output.
